{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFM_04_data_cleaning_and_split.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Optional, Tuple\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '{:.12f}'.format(x))\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('df_final_target_20250206.csv')\n",
    "    df2 = pd.read_csv('indicators/df2.csv')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Archivo no encontrado: {e.filename}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando datos.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_tipos_columnas_corto(df, df_nombre=\"DataFrame\"):\n",
    "    \"\"\"Analiza y muestra tipos de columnas y cuenta.\"\"\"\n",
    "\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(f\"{df_nombre} no es un DataFrame.\")\n",
    "        return\n",
    "\n",
    "    resultados = {\n",
    "        'booleano': [col for col in df.columns if pd.api.types.is_bool_dtype(df[col])],\n",
    "        'numérico': [col for col in df.columns if pd.api.types.is_numeric_dtype(df[col])],\n",
    "        'timestamp': [col for col in df.columns if pd.api.types.is_datetime64_any_dtype(df[col])],\n",
    "        'string': [col for col in df.columns if df[col].dtype == 'object'],\n",
    "        'otro': [col for col in df.columns if not any([\n",
    "            pd.api.types.is_bool_dtype(df[col]),\n",
    "            pd.api.types.is_numeric_dtype(df[col]),\n",
    "            pd.api.types.is_datetime64_any_dtype(df[col]),\n",
    "            df[col].dtype == 'object'\n",
    "        ])]\n",
    "    }\n",
    "\n",
    "    if not resultados:\n",
    "         print(f\"No se encontraron columnas en {df_nombre}.\")\n",
    "         return\n",
    "\n",
    "    for tipo, columnas in resultados.items():\n",
    "        print(f\"Tipo: {tipo.capitalize()}\")\n",
    "        print(f\"  Número: {len(columnas)}\")\n",
    "        if columnas:\n",
    "            max_cols_a_mostrar = 5\n",
    "            if len(columnas) > max_cols_a_mostrar:\n",
    "                 print(f\"  Columnas: {columnas[:max_cols_a_mostrar]}...\")\n",
    "            else:\n",
    "                 print(f\"  Columnas: {columnas}\")\n",
    "        else:\n",
    "            print(\"  No hay columnas.\")\n",
    "        print(\"-\" * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo: Booleano\n",
      "  Número: 13\n",
      "  Columnas: ['Doji', 'Hammer', 'HangingMan', 'BullishEngulfing', 'BearishEngulfing']...\n",
      "--------------------\n",
      "Tipo: Numérico\n",
      "  Número: 487\n",
      "  Columnas: ['open', 'high', 'low', 'close', 'volume']...\n",
      "--------------------\n",
      "Tipo: Timestamp\n",
      "  Número: 0\n",
      "  No hay columnas.\n",
      "--------------------\n",
      "Tipo: String\n",
      "  Número: 2\n",
      "  Columnas: ['timestamp', 'symbol']\n",
      "--------------------\n",
      "Tipo: Otro\n",
      "  Número: 0\n",
      "  No hay columnas.\n",
      "--------------------\n",
      "Tipo: Booleano\n",
      "  Número: 13\n",
      "  Columnas: ['Doji', 'Hammer', 'HangingMan', 'BullishEngulfing', 'BearishEngulfing']...\n",
      "--------------------\n",
      "Tipo: Numérico\n",
      "  Número: 467\n",
      "  Columnas: ['open', 'high', 'low', 'close', 'volume']...\n",
      "--------------------\n",
      "Tipo: Timestamp\n",
      "  Número: 0\n",
      "  No hay columnas.\n",
      "--------------------\n",
      "Tipo: String\n",
      "  Número: 2\n",
      "  Columnas: ['timestamp', 'symbol']\n",
      "--------------------\n",
      "Tipo: Otro\n",
      "  Número: 0\n",
      "  No hay columnas.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "analizar_tipos_columnas_corto(df)\n",
    "analizar_tipos_columnas_corto(df2, df_nombre=\"df2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir(df, timestamp_col='timestamp'):\n",
    "    \"\"\"Convierte columna timestamp a datetime y booleanos a int.\"\"\"\n",
    "    # Args: df (pd.DataFrame), timestamp_col (str)\n",
    "    # Return: pd.DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Entrada no es DataFrame.\")\n",
    "        return df\n",
    "\n",
    "    df_modificado = df.copy()\n",
    "\n",
    "    try:\n",
    "        if timestamp_col in df_modificado.columns:\n",
    "            df_modificado[timestamp_col] = pd.to_datetime(df_modificado[timestamp_col], errors='ignore')\n",
    "        else:\n",
    "             print(f\"Columna '{timestamp_col}' no existe.\")\n",
    "    except Exception:\n",
    "        print(f\"Fallo al convertir '{timestamp_col}'.\")\n",
    "\n",
    "    bool_cols = df_modificado.select_dtypes(include='bool').columns\n",
    "    if not bool_cols.empty:\n",
    "        df_modificado[bool_cols] = df_modificado[bool_cols].astype(int)\n",
    "\n",
    "    return df_modificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convertir(df)\n",
    "df2 = convertir(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Símbolos: 310\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values('timestamp')\n",
    "if 'symbol' in df.columns:\n",
    "    symbols = df['symbol'].unique()\n",
    "    print(f\"Símbolos: {len(symbols)}\")\n",
    "else:\n",
    "    symbols = ['unknown_symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes: 205\n",
      "Faltantes por columna:\n",
      "timestamp    205\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "total_missing = missing_values.sum()\n",
    "print(f\"Valores faltantes: {total_missing}\")\n",
    "missing_per_column = missing_values[missing_values > 0]\n",
    "if not missing_per_column.empty:\n",
    "    print(\"Faltantes por columna:\")\n",
    "    print(missing_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape df: (432450, 489)\n",
      "Shape df2: (1, 469)\n",
      "Columnas con NaN en df:\n",
      "['timestamp']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape df: {df.shape}\")\n",
    "print(f\"Shape df2: {df2.shape}\")\n",
    "\n",
    "columnas_con_nan = df.columns[df.isna().any()]\n",
    "\n",
    "if len(columnas_con_nan) > 0:\n",
    "    print(\"Columnas con NaN en df:\")\n",
    "    print(columnas_con_nan.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas únicas df: ['ATR_20_RollingMean', 'MFI_20', 'close_lead_1', 'close_lead_10', 'close_lead_11', 'close_lead_12', 'close_lead_13', 'close_lead_14', 'close_lead_15', 'close_lead_2', 'close_lead_3', 'close_lead_4', 'close_lead_5', 'close_lead_6', 'close_lead_7', 'close_lead_8', 'close_lead_9', 'future_max_increase_capped', 'is_sinusoid_shape', 'target']\n",
      "Columnas únicas df2: []\n"
     ]
    }
   ],
   "source": [
    "columnas_unicas_df = df.columns.difference(df2.columns)\n",
    "columnas_unicas_df2 = df2.columns.difference(df.columns)\n",
    "\n",
    "print(f\"Columnas únicas df:\", columnas_unicas_df.tolist())\n",
    "print(f\"Columnas únicas df2:\", columnas_unicas_df2.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\n",
    "    'ATR_20_RollingMean', 'MFI_20', 'is_sinusoid_shape', 'close_lead_1',\n",
    "    'close_lead_2', 'close_lead_3', 'close_lead_4', 'close_lead_5',\n",
    "    'close_lead_6', 'close_lead_7', 'close_lead_8', 'close_lead_9',\n",
    "    'close_lead_10', 'close_lead_11', 'close_lead_12', 'close_lead_13',\n",
    "    'close_lead_14', 'close_lead_15'\n",
    "]\n",
    "\n",
    "df.drop(columns=drop_columns, inplace=True, errors='ignore')\n",
    "df2.drop(columns=drop_columns, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas únicas en df post-drop: ['future_max_increase_capped', 'target']\n"
     ]
    }
   ],
   "source": [
    "if 'df' in locals() and isinstance(df, pd.DataFrame) and \\\n",
    "   'df2' in locals() and isinstance(df2, pd.DataFrame):\n",
    "\n",
    "    columnas_unicas_df_post_drop = df.columns.difference(df2.columns)\n",
    "    print(f\"Columnas únicas en df post-drop: {columnas_unicas_df_post_drop.tolist()}\")\n",
    "\n",
    "else:\n",
    "    if 'df' not in locals() or not isinstance(df, pd.DataFrame):\n",
    "         print(\"Variable df no válida.\")\n",
    "    if 'df2' not in locals() or not isinstance(df2, pd.DataFrame):\n",
    "         print(\"Variable df2 no válida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas coincidentes.\n"
     ]
    }
   ],
   "source": [
    "if 'df2' in locals() and isinstance(df2, pd.DataFrame) and not df2.empty:\n",
    "    fila_df2 = df2.iloc[0]\n",
    "\n",
    "    if 'timestamp' in df.columns and 'symbol' in df.columns and \\\n",
    "       'timestamp' in fila_df2.index and 'symbol' in fila_df2.index:\n",
    "\n",
    "        fila_df = df[(df['timestamp'] == fila_df2['timestamp']) & (df['symbol'] == fila_df2['symbol'])]\n",
    "\n",
    "        if not fila_df.empty:\n",
    "            fila_df_seleccionada = fila_df.iloc[0]\n",
    "            fila_df_dict = fila_df_seleccionada.to_dict()\n",
    "            fila_df2_dict = fila_df2.to_dict()\n",
    "\n",
    "            diferencias = {}\n",
    "            columnas_comunes = set(fila_df_dict.keys()) & set(fila_df2_dict.keys())\n",
    "\n",
    "            for col in columnas_comunes:\n",
    "                valor_df2 = fila_df2_dict[col]\n",
    "                valor_df = fila_df_dict[col]\n",
    "\n",
    "                if isinstance(valor_df2, float) and isinstance(valor_df, float):\n",
    "                    if not np.isclose(valor_df2, valor_df, atol=1e-8, equal_nan=True):\n",
    "                        diferencias[col] = (valor_df2, valor_df)\n",
    "                elif pd.isna(valor_df2) and pd.isna(valor_df):\n",
    "                     continue\n",
    "                else:\n",
    "                    if valor_df2 != valor_df:\n",
    "                        diferencias[col] = (valor_df2, valor_df)\n",
    "\n",
    "            if diferencias:\n",
    "                print(\"Diferencias fila 0 (df vs df2):\")\n",
    "                for col, (val_df2, val_df) in diferencias.items():\n",
    "                    print(f\"  {col}: df2={val_df2}, df={val_df}\")\n",
    "            else:\n",
    "                print(\"Filas coincidentes.\")\n",
    "        else:\n",
    "            print(\"No se encontró fila coincidente en df.\")\n",
    "    else:\n",
    "         print(\"Faltan columnas 'timestamp' o 'symbol'.\")\n",
    "else:\n",
    "     print(\"DataFrame df2 no válido o vacío.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe_types(\n",
    "    df: pd.DataFrame,\n",
    "    target_cols: Optional[List[str]] = None,\n",
    "    allowed_object_cols: Optional[List[str]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Prepara y verifica tipos de datos del DataFrame.\"\"\"\n",
    "\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Entrada no es DataFrame.\")\n",
    "        return df\n",
    "\n",
    "    df_processed = df.copy()\n",
    "    print(f\"Preparando tipos. Shape: {df_processed.shape}\")\n",
    "\n",
    "    bool_cols = df_processed.select_dtypes(include='bool').columns\n",
    "    if not bool_cols.empty:\n",
    "        print(f\"Convirtiendo booleanos: {list(bool_cols)}\")\n",
    "        try:\n",
    "            df_processed[bool_cols] = df_processed[bool_cols].astype(int)\n",
    "            if not df_processed.select_dtypes(include='bool').columns.empty:\n",
    "                 print(\"Fallo al convertir booleanos.\")\n",
    "        except Exception:\n",
    "            print(\"Error convirtiendo booleanos.\")\n",
    "    else:\n",
    "        print(\"No hay columnas booleanas.\")\n",
    "\n",
    "    object_cols = df_processed.select_dtypes(include='object').columns\n",
    "    permitidas = allowed_object_cols if allowed_object_cols is not None else []\n",
    "    problematic_object_cols = [col for col in object_cols if col not in permitidas]\n",
    "\n",
    "    if problematic_object_cols:\n",
    "        print(f\"Columnas 'object' no permitidas: {problematic_object_cols}.\")\n",
    "    else:\n",
    "         print(\"No hay columnas 'object' no permitidas.\")\n",
    "\n",
    "    if target_cols:\n",
    "        print(\"Verificando columnas objetivo.\")\n",
    "        targets_existentes = []\n",
    "        all_numeric = True\n",
    "        for col in target_cols:\n",
    "            if col in df_processed.columns:\n",
    "                targets_existentes.append(col)\n",
    "                dtype = df_processed[col].dtype\n",
    "                if not pd.api.types.is_numeric_dtype(df_processed[col]):\n",
    "                    print(f\"  Target '{col}' no numérico (Tipo: {dtype}).\")\n",
    "                    all_numeric = False\n",
    "            else:\n",
    "                print(f\"  Target '{col}' no encontrado.\")\n",
    "                all_numeric = False\n",
    "\n",
    "        if all_numeric and len(targets_existentes) == len(target_cols):\n",
    "            print(\"Targets numéricos y presentes.\")\n",
    "        elif not targets_existentes:\n",
    "             print(f\"Targets no encontrados.\")\n",
    "\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando tipos. Shape: (432450, 471)\n",
      "No hay columnas booleanas.\n",
      "No hay columnas 'object' no permitidas.\n",
      "Verificando columnas objetivo.\n",
      "Targets numéricos y presentes.\n",
      "Dimensiones df: (432450, 471)\n",
      "Preparando tipos. Shape: (1, 469)\n",
      "No hay columnas booleanas.\n",
      "No hay columnas 'object' no permitidas.\n",
      "Verificando columnas objetivo.\n",
      "  Target 'target' no encontrado.\n",
      "  Target 'future_max_increase_capped' no encontrado.\n",
      "Targets no encontrados.\n",
      "Dimensiones df2: (1, 469)\n"
     ]
    }
   ],
   "source": [
    "cols_objetivo = ['target', 'future_max_increase_capped']\n",
    "cols_object_ok = ['symbol','timestamp']\n",
    "\n",
    "df = prepare_dataframe_types(\n",
    "    df,\n",
    "    target_cols=cols_objetivo,\n",
    "    allowed_object_cols=cols_object_ok\n",
    ")\n",
    "print(f\"Dimensiones df: {df.shape}\")\n",
    "\n",
    "df2 = prepare_dataframe_types(\n",
    "    df2,\n",
    "    target_cols=cols_objetivo,\n",
    "    allowed_object_cols=cols_object_ok\n",
    ")\n",
    "print(f\"Dimensiones df2: {df2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()\n",
    "df4 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'timestamp' in df3.columns:\n",
    "    df3['timestamp'] = pd.to_datetime(df3['timestamp'], errors='coerce')\n",
    "else:\n",
    "    print(\"Columna 'timestamp' no encontrada en df3.\")\n",
    "\n",
    "expected_bool_cols = df3.select_dtypes(include=['bool']).columns.tolist()\n",
    "if expected_bool_cols:\n",
    "     print(f\"Columnas booleanas inesperadas en df3: {expected_bool_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_columnes_iguals(df, num_inicial=3, num_final=500):\n",
    "    \"\"\"Detecta columnas idénticas en un DataFrame.\"\"\"\n",
    "\n",
    "    iguals = defaultdict(list)\n",
    "    columnes = df.columns\n",
    "\n",
    "    if len(df) == 0:\n",
    "        return dict(iguals)\n",
    "\n",
    "    df_mini = df.iloc[:min(num_inicial, len(df))].copy()\n",
    "\n",
    "    grupos_iniciales = defaultdict(list)\n",
    "    for col in columnes:\n",
    "        try:\n",
    "            col_hash = hash(str(df_mini[col].values.tobytes()))\n",
    "            grupos_iniciales[col_hash].append(col)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    grupos_candidatos = [cols for cols in grupos_iniciales.values() if len(cols) > 1]\n",
    "\n",
    "    muestras = [10, 50, 100, num_final] if num_final > 100 else [min(len(df), num_final)]\n",
    "    muestras = [m for m in muestras if m <= len(df)]\n",
    "\n",
    "    for num_muestra in muestras:\n",
    "        if not grupos_candidatos:\n",
    "            break\n",
    "\n",
    "        df_muestra = df.iloc[:num_muestra].copy()\n",
    "        nuevos_grupos = []\n",
    "        for grupo in grupos_candidatos:\n",
    "            subgrupos = defaultdict(list)\n",
    "            for col in grupo:\n",
    "                try:\n",
    "                    col_hash = hash(str(df_muestra[col].values.tobytes()))\n",
    "                    subgrupos[col_hash].append(col)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            nuevos_grupos.extend([cols for cols in subgrupos.values() if len(cols) > 1])\n",
    "        grupos_candidatos = nuevos_grupos\n",
    "\n",
    "    columnes_processades = set()\n",
    "    for grupo in grupos_candidatos:\n",
    "        if not grupo: continue\n",
    "        col_base = grupo[0]\n",
    "        if col_base in columnes_processades: continue\n",
    "\n",
    "        for col_comp in grupo[1:]:\n",
    "            if col_comp in columnes_processades:\n",
    "                continue\n",
    "\n",
    "            if df[col_base].equals(df[col_comp]):\n",
    "                iguals[col_base].append(col_comp)\n",
    "                columnes_processades.add(col_comp)\n",
    "\n",
    "    return dict(iguals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_relacions_factorials(df, num_inicial=3, num_final=500, tolerancia=1e-6):\n",
    "    \"\"\"Detecta relaciones factoriales entre columnas numéricas.\"\"\"\n",
    "\n",
    "    relacions = defaultdict(list)\n",
    "    columnes_numeriques = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "    if len(df) == 0 or len(columnes_numeriques) < 2:\n",
    "        return dict(relacions)\n",
    "\n",
    "    df_mini = df.iloc[:min(num_inicial, len(df))].copy()\n",
    "\n",
    "    columnes_no_constantes = [\n",
    "        col for col in columnes_numeriques\n",
    "        if df_mini[col].nunique(dropna=False) > 1\n",
    "    ]\n",
    "\n",
    "    firmas = {}\n",
    "    for col in columnes_no_constantes:\n",
    "        vals = df_mini[col].replace([np.inf, -np.inf], np.nan).dropna().values\n",
    "        if len(vals) > 0:\n",
    "            idx_no_zero = np.where(vals != 0)[0]\n",
    "            if len(idx_no_zero) > 0:\n",
    "                first_nonzero = vals[idx_no_zero[0]]\n",
    "\n",
    "                firma = tuple(np.round(vals / first_nonzero, 6))\n",
    "                firmas[col] = firma\n",
    "\n",
    "    grupos_firmas = defaultdict(list)\n",
    "    for col, firma in firmas.items():\n",
    "        grupos_firmas[firma].append(col)\n",
    "\n",
    "    pares_candidatos = []\n",
    "    for grupo in grupos_firmas.values():\n",
    "        if len(grupo) > 1:\n",
    "            for i in range(len(grupo)):\n",
    "                for j in range(i + 1, len(grupo)):\n",
    "                    pares_candidatos.append((grupo[i], grupo[j]))\n",
    "\n",
    "    muestras = [10, 50, 100, num_final] if num_final > 100 else [min(len(df), num_final)]\n",
    "    muestras = [m for m in muestras if m <= len(df)]\n",
    "    pares_confirmados_temporal = []\n",
    "\n",
    "    for num_muestra in muestras:\n",
    "        if not pares_candidatos:\n",
    "            break\n",
    "\n",
    "        df_muestra = df.iloc[:num_muestra].copy()\n",
    "        nuevos_pares_confirmados = []\n",
    "        pares_para_siguiente_ronda = []\n",
    "\n",
    "        for col_a_nom, col_b_nom in pares_candidatos:\n",
    "            col_a = df_muestra[col_a_nom]\n",
    "            col_b = df_muestra[col_b_nom]\n",
    "            factor_encontrado = None\n",
    "            relacion = None \n",
    "\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                factors_ab = (col_a / col_b).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "            if len(factors_ab) > 0 and factors_ab.nunique() == 1:\n",
    "                 factor_encontrado = factors_ab.iloc[0]\n",
    "                 relacion = 'ab'\n",
    "\n",
    "            if factor_encontrado is None:\n",
    "                 with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                     factors_ba = (col_b / col_a).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "                 if len(factors_ba) > 0 and factors_ba.nunique() == 1:\n",
    "                     factor_encontrado = factors_ba.iloc[0]\n",
    "                     relacion = 'ba'\n",
    "\n",
    "            if factor_encontrado is not None:\n",
    "                 nuevos_pares_confirmados.append((col_a_nom, col_b_nom, factor_encontrado, relacion))\n",
    "                 pares_para_siguiente_ronda.append((col_a_nom, col_b_nom))\n",
    "\n",
    "        pares_candidatos = pares_para_siguiente_ronda\n",
    "        pares_confirmados_temporal = nuevos_pares_confirmados \n",
    "        \n",
    "        if not pares_candidatos:\n",
    "             break\n",
    "\n",
    "    relacions_trobades = set()\n",
    "    for col_a_nom, col_b_nom, factor, tipo in pares_confirmados_temporal:\n",
    "        if (col_a_nom, col_b_nom) in relacions_trobades or (col_b_nom, col_a_nom) in relacions_trobades:\n",
    "            continue\n",
    "\n",
    "        col_a_full = df[col_a_nom].fillna(0).values\n",
    "        col_b_full = df[col_b_nom].fillna(0).values\n",
    "\n",
    "        try:\n",
    "            if tipo == 'ab':\n",
    "                comparison = np.isclose(col_a_full, factor * col_b_full, atol=tolerancia, rtol=tolerancia, equal_nan=True)\n",
    "                if np.all(comparison):\n",
    "                    relacions[col_a_nom].append((col_b_nom, factor))\n",
    "                    relacions_trobades.add((col_a_nom, col_b_nom))\n",
    "            else: \n",
    "                comparison = np.isclose(col_b_full, factor * col_a_full, atol=tolerancia, rtol=tolerancia, equal_nan=True)\n",
    "                if np.all(comparison):\n",
    "                    relacions[col_b_nom].append((col_a_nom, factor))\n",
    "                    relacions_trobades.add((col_b_nom, col_a_nom))\n",
    "        except Exception:\n",
    "\n",
    "             continue\n",
    "\n",
    "    return dict(relacions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectando columnas iguales...\n",
      "Detectando relaciones factoriales...\n",
      "--- Resultados ---\n",
      "Columnas idénticas:\n",
      "  open: ['open_lag_0']\n",
      "  high: ['high_lag_0']\n",
      "  low: ['low_lag_0']\n",
      "  close: ['close_lag_0', 'close_lead_0']\n",
      "  volume: ['volume_lag_0']\n",
      "  quote_asset_volume: ['quote_asset_volume_lag_0']\n",
      "  number_of_trades: ['number_of_trades_lag_0']\n",
      "  taker_buy_base_asset_volume: ['taker_buy_base_asset_volume_lag_0']\n",
      "  taker_buy_quote_asset_volume: ['taker_buy_quote_asset_volume_lag_0', 'TakerBuyQuoteVolume']\n",
      "  SMA_20: ['BB_Middle_20']\n",
      "  Hammer: ['HangingMan']\n",
      "  ADX: ['dx_smoothed_lag_1']\n",
      "  ATR_14: ['ATR_14_lag_0', 'ATR_14_lag_1', 'ATR_14_lag_2', 'ATR_14_lag_3', 'ATR_14_lag_4', 'ATR_14_lag_5', 'ATR_14_lag_6', 'ATR_14_lag_7', 'ATR_14_lag_8', 'ATR_14_lag_9', 'ATR_14_lag_10', 'ATR_14_lag_11', 'ATR_14_lag_12', 'ATR_14_lag_13', 'ATR_14_RollingMean']\n",
      "Relaciones factoriales:\n",
      "  open: [('open_lag_0', '1')]\n",
      "  high: [('high_lag_0', '1')]\n",
      "  low: [('low_lag_0', '1')]\n",
      "  close: [('close_lag_0', '1'), ('close_lead_0', '1')]\n",
      "  close_lag_0: [('close_lead_0', '1')]\n",
      "  volume: [('volume_lag_0', '1')]\n",
      "  quote_asset_volume: [('quote_asset_volume_lag_0', '1')]\n",
      "  number_of_trades: [('number_of_trades_lag_0', '1')]\n",
      "  taker_buy_base_asset_volume: [('taker_buy_base_asset_volume_lag_0', '1')]\n",
      "  taker_buy_quote_asset_volume: [('taker_buy_quote_asset_volume_lag_0', '1'), ('TakerBuyQuoteVolume', '1')]\n",
      "  taker_buy_quote_asset_volume_lag_0: [('TakerBuyQuoteVolume', '1')]\n",
      "  SMA_20: [('BB_Middle_20', '1')]\n",
      "  ATR_14: [('ATR_14_lag_0', '1'), ('ATR_14_lag_1', '1'), ('ATR_14_lag_2', '1'), ('ATR_14_lag_3', '1'), ('ATR_14_lag_4', '1'), ('ATR_14_lag_5', '1'), ('ATR_14_lag_6', '1'), ('ATR_14_lag_7', '1'), ('ATR_14_lag_8', '1'), ('ATR_14_lag_9', '1'), ('ATR_14_lag_10', '1'), ('ATR_14_lag_11', '1'), ('ATR_14_lag_12', '1'), ('ATR_14_lag_13', '1'), ('ATR_14_RollingMean', '1')]\n",
      "  ATR_14_lag_0: [('ATR_14_lag_1', '1'), ('ATR_14_lag_2', '1'), ('ATR_14_lag_3', '1'), ('ATR_14_lag_4', '1'), ('ATR_14_lag_5', '1'), ('ATR_14_lag_6', '1'), ('ATR_14_lag_7', '1'), ('ATR_14_lag_8', '1'), ('ATR_14_lag_9', '1'), ('ATR_14_lag_10', '1'), ('ATR_14_lag_11', '1'), ('ATR_14_lag_12', '1'), ('ATR_14_lag_13', '1'), ('ATR_14_RollingMean', '1')]\n",
      "  ATR_14_lag_1: [('ATR_14_lag_2', '1'), ('ATR_14_lag_3', '1'), ('ATR_14_lag_4', '1'), ('ATR_14_lag_5', '1'), ('ATR_14_lag_6', '1'), ('ATR_14_lag_7', '1'), ('ATR_14_lag_8', '1'), ('ATR_14_lag_9', '1'), ('ATR_14_lag_10', '1'), ('ATR_14_lag_11', '1'), ('ATR_14_lag_12', '1'), ('ATR_14_lag_13', '1'), ('ATR_14_RollingMean', '1')]\n",
      "  ATR_14_lag_2: [('ATR_14_lag_3', '1'), ('ATR_14_lag_4', '1'), ('ATR_14_lag_5', '1'), ('ATR_14_lag_6', '1'), ('ATR_14_lag_7', '1'), ('ATR_14_lag_8', '1'), ('ATR_14_lag_9', '1'), ('ATR_14_lag_10', '1'), ('ATR_14_lag_11', '1'), ('ATR_14_lag_12', '1'), ('ATR_14_lag_13', '1'), ('ATR_14_RollingMean', '1')]\n",
      "  ATR_14_lag_3: [('ATR_14_lag_4', '1'), ('ATR_14_lag_5', '1'), ('ATR_14_lag_6', '1'), ('ATR_14_lag_7', '1'), ('ATR_14_lag_8', '1'), ('ATR_14_lag_9', '1'), ('ATR_14_lag_10', '1'), ('ATR_14_lag_11', '1'), ('ATR_14_lag_12', '1'), ('ATR_14_lag_13', '1'), ('ATR_14_RollingMean', '1')]\n",
      "  ATR_14_lag_4: [('ATR_14_lag_5', '1'), ('ATR_14_lag_6', '1'), ('ATR_14_lag_7', '1'), ('ATR_14_lag_8', '1'), ('ATR_14_lag_9', '1'), ('ATR_14_lag_10', '1'), ('ATR_14_lag_11', '1'), ('ATR_14_lag_12', '1'), ('ATR_14_lag_13', '1'), ('ATR_14_RollingMean', '1')]\n",
      "  ATR_14_lag_5: [('ATR_14_lag_6', '1'), ('ATR_14_lag_7', '1'), ('ATR_14_lag_8', '1'), ('ATR_14_lag_9', '1'), ('ATR_14_lag_10', '1'), ('ATR_14_lag_11', '1'), ('ATR_14_lag_12', '1'), ('ATR_14_lag_13', '1'), ('ATR_14_RollingMean', '1')]\n",
      "  ATR_14_lag_6: [('ATR_14_lag_7', '1'), ('ATR_14_lag_8', '1'), ('ATR_14_lag_9', '1'), ('ATR_14_lag_10', '1'), ('ATR_14_lag_11', '1'), ('ATR_14_lag_12', '1'), ('ATR_14_lag_13', '1'), ('ATR_14_RollingMean', '1')]\n",
      "  ATR_14_lag_7: [('ATR_14_lag_8', '1'), ('ATR_14_lag_9', '1'), ('ATR_14_lag_10', '1'), ('ATR_14_lag_11', '1'), ('ATR_14_lag_12', '1'), ('ATR_14_lag_13', '1'), ('ATR_14_RollingMean', '1')]\n",
      "  ATR_14_lag_8: [('ATR_14_lag_9', '1'), ('ATR_14_lag_10', '1'), ('ATR_14_lag_11', '1'), ('ATR_14_lag_12', '1'), ('ATR_14_lag_13', '1'), ('ATR_14_RollingMean', '1')]\n",
      "  ATR_14_lag_9: [('ATR_14_lag_10', '1'), ('ATR_14_lag_11', '1'), ('ATR_14_lag_12', '1'), ('ATR_14_lag_13', '1'), ('ATR_14_RollingMean', '1')]\n",
      "  ATR_14_lag_10: [('ATR_14_lag_11', '1'), ('ATR_14_lag_12', '1'), ('ATR_14_lag_13', '1'), ('ATR_14_RollingMean', '1')]\n",
      "  ATR_14_lag_11: [('ATR_14_lag_12', '1'), ('ATR_14_lag_13', '1'), ('ATR_14_RollingMean', '1')]\n",
      "  ATR_14_lag_12: [('ATR_14_lag_13', '1'), ('ATR_14_RollingMean', '1')]\n",
      "  ATR_14_lag_13: [('ATR_14_RollingMean', '1')]\n",
      "Columnas eliminadas (si existían). Shape df3: (432450, 442), Shape df4: (1, 440)\n"
     ]
    }
   ],
   "source": [
    "df_analisis = df3.copy() \n",
    "\n",
    "print(\"Detectando columnas iguales...\")\n",
    "columnes_iguals = detectar_columnes_iguals(df_analisis)\n",
    "\n",
    "print(\"Detectando relaciones factoriales...\")\n",
    "relacions_factorials = detectar_relacions_factorials(df_analisis)\n",
    "\n",
    "print(\"--- Resultados ---\")\n",
    "if columnes_iguals:\n",
    "    print(\"Columnas idénticas:\")\n",
    "    for col, duplicats in columnes_iguals.items():\n",
    "        print(f\"  {col}: {duplicats}\")\n",
    "else:\n",
    "    print(\"No hay columnas idénticas.\")\n",
    "\n",
    "if relacions_factorials:\n",
    "    print(\"Relaciones factoriales:\")\n",
    "    for col, relacionats in relacions_factorials.items():\n",
    "        rel_formateada = [(nom, f\"{factor:.6g}\") for nom, factor in relacionats]\n",
    "        print(f\"  {col}: {rel_formateada}\")\n",
    "else:\n",
    "    print(\"No hay relaciones factoriales.\")\n",
    "\n",
    "columnes_a_suprimir = [\n",
    "    'open_lag_0', 'high_lag_0', 'low_lag_0', 'close_lag_0', 'close_lead_0', 'volume_lag_0',\n",
    "    'quote_asset_volume_lag_0', 'number_of_trades_lag_0', 'taker_buy_base_asset_volume_lag_0',\n",
    "    'taker_buy_quote_asset_volume_lag_0', 'TakerBuyQuoteVolume', 'BB_Middle_20', 'HangingMan',\n",
    "    'dx_smoothed_lag_1', 'ATR_14_lag_0', 'ATR_14_lag_1', 'ATR_14_lag_2', 'ATR_14_lag_3',\n",
    "    'ATR_14_lag_4', 'ATR_14_lag_5', 'ATR_14_lag_6', 'ATR_14_lag_7', 'ATR_14_lag_8',\n",
    "    'ATR_14_lag_9', 'ATR_14_lag_10', 'ATR_14_lag_11', 'ATR_14_lag_12', 'ATR_14_lag_13',\n",
    "    'ATR_14_RollingMean'\n",
    "]\n",
    "\n",
    "df3 = df3.drop(columns=columnes_a_suprimir, errors='ignore')\n",
    "df4 = df4.drop(columns=columnes_a_suprimir, errors='ignore')\n",
    "\n",
    "print(f\"Columnas eliminadas (si existían). Shape df3: {df3.shape}, Shape df4: {df4.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_simbolos_por_targets(\n",
    "    df: pd.DataFrame,\n",
    "    col_simbolo: str = 'symbol',\n",
    "    col_target: str = 'target',\n",
    "    valor_target_positivo: int = 1,\n",
    "    min_targets_positivos: int = 1\n",
    ") -> Tuple[pd.DataFrame, List[str], List[str]]:\n",
    "    \"\"\"Filtra DataFrame manteniendo símbolos con un mínimo de targets positivos.\"\"\"\n",
    "\n",
    "    if col_simbolo not in df.columns or col_target not in df.columns:\n",
    "        print(f\"Columnas requeridas no encontradas.\")\n",
    "        simbolos_presentes = list(df[col_simbolo].unique()) if col_simbolo in df.columns else []\n",
    "        return df, simbolos_presentes, []\n",
    "\n",
    "    simbolos_originales = df[col_simbolo].unique()\n",
    "    print(f\"Evaluando {len(simbolos_originales)} símbolos.\")\n",
    "\n",
    "    conteo_por_simbolo = df[df[col_target] == valor_target_positivo].groupby(col_simbolo)[col_target].count()\n",
    "    simbolos_a_mantener = conteo_por_simbolo[conteo_por_simbolo >= min_targets_positivos].index.tolist()\n",
    "    simbolos_eliminados = list(set(simbolos_originales) - set(simbolos_a_mantener))\n",
    "\n",
    "    print(\"Filtrado completado.\")\n",
    "    print(f\"  Símbolos mantenidos: {len(simbolos_a_mantener)}\")\n",
    "    print(f\"  Símbolos eliminados: {len(simbolos_eliminados)}\")\n",
    "\n",
    "    if not simbolos_a_mantener:\n",
    "        print(\"Ningún símbolo cumple el criterio.\")\n",
    "        return pd.DataFrame(columns=df.columns), [], list(simbolos_originales)\n",
    "\n",
    "    df_filtrado = df[df[col_simbolo].isin(simbolos_a_mantener)].copy()\n",
    "    print(f\"Shape antes del filtro: {df.shape}\")\n",
    "    print(f\"Shape después del filtro: {df_filtrado.shape}\")\n",
    "\n",
    "    return df_filtrado, simbolos_a_mantener, simbolos_eliminados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando 310 símbolos.\n",
      "Filtrado completado.\n",
      "  Símbolos mantenidos: 77\n",
      "  Símbolos eliminados: 233\n",
      "Shape antes del filtro: (432450, 442)\n",
      "Shape después del filtro: (107415, 442)\n",
      "DataFrame 'df3' actualizado tras filtro.\n"
     ]
    }
   ],
   "source": [
    "columna_id = 'symbol'\n",
    "columna_objetivo = 'target'\n",
    "valor_positivo = 1\n",
    "minimo_requerido = 1\n",
    "\n",
    "df_filtrado_targets, simbolos_validos, simbolos_fuera = filtrar_simbolos_por_targets(\n",
    "    df=df3,\n",
    "    col_simbolo=columna_id,\n",
    "    col_target=columna_objetivo,\n",
    "    valor_target_positivo=valor_positivo,\n",
    "    min_targets_positivos=minimo_requerido\n",
    ")\n",
    "\n",
    "df3 = df_filtrado_targets\n",
    "print(\"DataFrame 'df3' actualizado tras filtro.\")\n",
    "\n",
    "if df3.empty:\n",
    "    print(\"DataFrame 'df3' vacío después del filtrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_dataframe_train_test(df, columna_tiempo, columnas_para_quitar,\n",
    "                                 ratio_train, carpeta_salida, prefijo):\n",
    "    \"\"\"Divide DataFrame en train/test por tiempo y guarda en CSV.\"\"\"\n",
    "\n",
    "\n",
    "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "        print(\"DataFrame vacío o inválido.\")\n",
    "        return\n",
    "\n",
    "    df_copia = df.copy()\n",
    "\n",
    "    if columna_tiempo in df_copia.columns:\n",
    "        print(f\"Ordenando por '{columna_tiempo}'\")\n",
    "        df_copia = df_copia.sort_values(by=columna_tiempo).reset_index(drop=True)\n",
    "    else:\n",
    "        print(f\"Columna '{columna_tiempo}' no encontrada para ordenar.\")\n",
    "\n",
    "\n",
    "    if columnas_para_quitar:\n",
    "        cols_existentes = [col for col in columnas_para_quitar if col in df_copia.columns]\n",
    "        if cols_existentes:\n",
    "            df_copia = df_copia.drop(columns=cols_existentes)\n",
    "            print(f\"Columnas eliminadas: {cols_existentes}\")\n",
    "\n",
    "    n_filas = len(df_copia)\n",
    "    n_train = int(n_filas * ratio_train)\n",
    "    n_test = n_filas - n_train\n",
    "    print(f\"Filas: {n_filas}, Train: {n_train}, Test: {n_test}\")\n",
    "\n",
    "    if n_train <= 0 or n_test <= 0:\n",
    "        print(f\"División inválida (Train={n_train}, Test={n_test}).\")\n",
    "        return\n",
    "\n",
    "    df_train = df_copia.iloc[:n_train]\n",
    "    df_test = df_copia.iloc[n_train:]\n",
    "    print(f\"Shape df_train: {df_train.shape}, Shape df_test: {df_test.shape}\")\n",
    "\n",
    "    try:\n",
    "        os.makedirs(carpeta_salida, exist_ok=True)\n",
    "    except OSError as e:\n",
    "        print(f\"Error creando carpeta '{carpeta_salida}'.\")\n",
    "        return\n",
    "\n",
    "    nombre_train = os.path.join(carpeta_salida, f\"{prefijo}_train_completo.csv\")\n",
    "    nombre_test = os.path.join(carpeta_salida, f\"{prefijo}_test_completo.csv\")\n",
    "    try:\n",
    "        df_train.to_csv(nombre_train, index=False) \n",
    "        df_test.to_csv(nombre_test, index=False)\n",
    "        print(f\"Guardado: {nombre_train}\")\n",
    "        print(f\"Guardado: {nombre_test}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error guardando archivos CSV.\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordenando por 'timestamp'\n",
      "Filas: 107415, Train: 85932, Test: 21483\n",
      "Shape df_train: (85932, 442), Shape df_test: (21483, 442)\n",
      "Guardado: datos_divididos\\datos_financieros_train_completo.csv\n",
      "Guardado: datos_divididos\\datos_financieros_test_completo.csv\n",
      "\n",
      "Proceso de división finalizado. Archivos en 'datos_divididos'\n"
     ]
    }
   ],
   "source": [
    "columnas_a_ignorar = []\n",
    "carpeta_destino = \"datos_divididos\"\n",
    "nombre_base = \"datos_financieros\"\n",
    "proporcion_entrenamiento = 0.8\n",
    "\n",
    "dividir_dataframe_train_test(\n",
    "    df = df3,\n",
    "    columna_tiempo = 'timestamp',\n",
    "    columnas_para_quitar = columnas_a_ignorar,\n",
    "    ratio_train = proporcion_entrenamiento,\n",
    "    carpeta_salida = carpeta_destino,\n",
    "    prefijo = nombre_base\n",
    ")\n",
    "\n",
    "print(f\"\\nProceso de división finalizado. Archivos en '{carpeta_destino}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
